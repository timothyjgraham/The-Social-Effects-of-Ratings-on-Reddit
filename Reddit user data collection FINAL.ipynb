{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, json\n",
    "import datetime as dt\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 \n",
    "\n",
    "## Data collection - collect Reddit user comment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can manually create a list of users, and the script will collect their entire comment history from Reddit, \n",
    "# and write it file in a sub-directory called 'user_data'.\n",
    "\n",
    "users = ['USER_1_NAME_HERE','USER_2_NAME_HERE','USER_N_NAME_HERE']\n",
    "\n",
    "for name in users:\n",
    "    sub_csv = open('user_data/' + name + '_submissions.csv', 'w')\n",
    "    sub_csv.write(\"title, body, score, id, url, num_comments(approx.), created \\n\")\n",
    "    total = 1001\n",
    "    before_field = \"0d\"\n",
    "    while(total > 1000):\n",
    "        url = urlopen(\"https://api.pushshift.io/reddit/submission/search?metadata=true&before=\" + before_field + \"&limit=1000&sort=desc&author=\" + name)\n",
    "        # url = urlopen(\"https://api.pushshift.io/reddit/submission/search?subreddit=\" + sub + \"&metadata=true&before=\" + before_field + \"&limit=1000&sort=desc&author=\" + name)\n",
    "        user_data = json.loads(url.read().decode())\n",
    "        sub_num = user_data[\"metadata\"][\"results_returned\"]\n",
    "        total = user_data[\"metadata\"][\"total_results\"]\n",
    "        for j in range(0, sub_num):\n",
    "            submission = user_data[\"data\"][j]\n",
    "            sub_csv.write('' .join([i if ord(i) < 128 else ' ' for i in submission[\"title\"].replace(\",\", \"\").replace(\"\\n\", \".\")]) + \",\")\n",
    "            try:\n",
    "                sub_csv.write('' .join([i if ord(i) < 128 else ' ' for i in submission[\"selftext\"].replace(\",\", \"\").replace(\"\\n\", \".\")]) + \",\")\n",
    "            except KeyError:\n",
    "                sub_csv.write(\"[none],\")\n",
    "            sub_csv.write(str(submission[\"score\"]) + \",\")\n",
    "            sub_csv.write('' .join([i if ord(i) < 128 else ' ' for i in submission[\"id\"].replace(\",\", \"\").replace(\"\\n\", \".\")]) + \",\")\n",
    "            sub_csv.write('' .join([i if ord(i) < 128 else ' ' for i in submission[\"url\"].replace(\",\", \"\").replace(\"\\n\", \".\")]) + \",\")\n",
    "            sub_csv.write('' .join([i if ord(i) < 128 else ' ' for i in str(submission[\"num_comments\"]).replace(\",\", \"\").replace(\"\\n\", \".\")]) + \",\")\n",
    "            sub_csv.write(dt.datetime.fromtimestamp(submission[\"created_utc\"]).isoformat() + \"\\n\")\n",
    "            if(j == sub_num -1):\n",
    "                before_field = str(user_data[\"data\"][sub_num - 1][\"created_utc\"])\n",
    "    sub_csv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "## Data already collected and saved to disk (Step 1 above). \n",
    "\n",
    "## Ready to import and analyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get a list of all the user data files \n",
    "user_files = os.listdir('user_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL - READ IN EXISTING FILE IF ALREADY PROCESSED\n",
    "# final_results = pd.read_csv(\"final_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CharlieDay77_comments.csv',\n",
       " 'scubareddit12_comments.csv',\n",
       " 'SUB_05_comments.csv',\n",
       " 'SirRonaldofBurgundy_comments.csv',\n",
       " 'RollAd20_comments.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9769"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will store all the data in this list:\n",
    "votescore_and_mean_sentiment = []\n",
    "\n",
    "# loop through all file names in the directory:\n",
    "for user_filename in user_files:\n",
    "    \n",
    "    try:\n",
    "        test_user_comments = pd.read_csv('user_data/' + user_filename)\n",
    "        test_user_comments.columns = ['submission_id', 'parent_id', 'body', 'id', 'created', 'score']\n",
    "        test_user_comments['created_fixed'] = pd.DatetimeIndex(test_user_comments['created'])\n",
    "        test_user_comments['created_fixed_unix'] = test_user_comments['created_fixed'].astype(np.int64) // 10**9\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    for index, row in test_user_comments.iterrows():\n",
    "        temp_df = test_user_comments[(test_user_comments['created_fixed_unix'] < row['created_fixed_unix'] + (60*60)) & \n",
    "                       (test_user_comments['created_fixed_unix'] > row['created_fixed_unix'])]\n",
    "\n",
    "        if(len(temp_df)==0):\n",
    "            continue\n",
    "\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for text in temp_df['body']:\n",
    "            try:\n",
    "                sentiment_scores.append(analyser.polarity_scores(text))\n",
    "            except:\n",
    "                sentiment_scores.append({'neg': 0, 'neu': 0, 'pos': 0, 'compound': 0})\n",
    "\n",
    "        sentiment_compound_scores = [item['compound'] for item in sentiment_scores]\n",
    "\n",
    "        node_id_temp = row['id']\n",
    "        vote_score_temp = row['score']\n",
    "        mean_sent_score = statistics.mean(sentiment_compound_scores)\n",
    "\n",
    "        votescore_and_mean_sentiment.append({\n",
    "            'id': node_id_temp, \n",
    "            'score': vote_score_temp,\n",
    "            'mean_sentiment_score': mean_sent_score\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.DataFrame(votescore_and_mean_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "final_results.to_csv(r'final_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
